{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m chat \u001b[39m=\u001b[39m ChatOpenAI(temperature\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m,model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39mchat, prompt\u001b[39m=\u001b[39mchat_prompt_template)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(chain\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mcolorful socks\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py:213\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    109\u001b[0m     inputs,\n\u001b[1;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py:57\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py:118\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m    117\u001b[0m     \u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py:62\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list)\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(prompts, stop)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chat_models/base.py:72\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chat_models/base.py:69\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m     66\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompt_strings, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     70\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chat_models/base.py:50\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m, messages: List[List[BaseMessage]], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Top Level call\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     results \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chat_models/base.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m, messages: List[List[BaseMessage]], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Top Level call\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     results \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chat_models/openai.py:246\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    242\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    243\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[0;32m--> 246\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m _create_chat_result(response)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/langchain/chat_models/openai.py:222\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 222\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9,model_name='gpt-3.5-turbo')\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "print(chain.run(\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI \n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.chains.llm import LLMChain\n",
    "from cot import Collection\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# from dataloader import to_Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=.0,model_name=\"gpt-4\")   #text-davinci-003\n",
    "#llm = ChatOpenAI(temperature=.0,model_name=\"gpt-3.5-turbo\")  \n",
    "\n",
    "reflect_template = \"\"\"\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    {cot_trigger} {cot}\n",
    "    {answer_extraction} {answer}\n",
    "    \n",
    "    Reflection: {reflection_prompt}\n",
    "    \"\"\"\n",
    "reflect_prompt_template = PromptTemplate(input_variables=[\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt'], template=reflect_template)\n",
    "reflect_chain = LLMChain(llm=llm, prompt=reflect_prompt_template,output_key=\"reflection\")\n",
    "\n",
    "#{instruction}\n",
    "extraction_template = \"\"\"\n",
    "\n",
    "    Question: {question}\n",
    "    Answer_choices: {answer_choices}\n",
    "\n",
    "    {cot_trigger} {cot}\n",
    "    {answer_extraction} {answer}\n",
    "    \n",
    "    Reflection: {reflection_prompt}\n",
    "    {reflection}\n",
    "\n",
    "    {reflect_answer_extraction}\n",
    "    \"\"\"\n",
    "    #Get reflection\n",
    "ans_prompt_template = PromptTemplate(input_variables=[\"question\",\"answer_choices\",\"cot_trigger\",\"cot\",\"answer_extraction\",'answer','reflection_prompt','reflection','reflect_answer_extraction'], template=extraction_template)\n",
    "reflect_answer_chain = LLMChain(llm=llm, prompt=ans_prompt_template,output_key=\"reflection_answer\")\n",
    "\n",
    "    # This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SequentialChain\n",
    "reflect_overall_chain = SequentialChain(chains=[reflect_chain, reflect_answer_chain],input_variables=[\"question\",\"answer_choices\",\"cot_trigger\",\"answer_extraction\",'cot','answer','reflection_prompt','reflect_answer_extraction'],\n",
    "        output_variables=[\"reflection\", \"reflection_answer\"],\n",
    "        verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Answer the following question through step-by-step reasoning.\"\n",
    "question = \"Animals may fight, make threatening sounds, and act aggressively toward members of the same species. These behaviors usually occur as the result of\",\n",
    "answer_choices = [\n",
    "                    \"competition\",\n",
    "                    \"conservation\",\n",
    "                    \"decomposition\",\n",
    "                    \"pollution\"\n",
    "                ]\n",
    "cot_trigger = \"Answer: Let's think step by step.\"\n",
    "cot = \"Aggression is needed to defend something, one needs to defend their spot when they are in competition\"\n",
    "answer_extraction = \"Therefore, the answer is\"\n",
    "answer = \"competition\"\n",
    "reflection_prompt = \"do you agree with the cot yes or no\"\n",
    "reflection = \"Great reasoning mate!\"\n",
    "reflect_answer_extraction = \"Based on the text above the answer is:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Question: ('Animals may fight, make threatening sounds, and act aggressively toward members of the same species. These behaviors usually occur as the result of',)\n",
      "    Answer_choices: ['competition', 'conservation', 'decomposition', 'pollution']\n",
      "\n",
      "    Answer: Let's think step by step.Aggression is needed to defend something, one needs to defend their spot when they are in competition\n",
      "    Therefore, the answer is competition\n",
      "    \n",
      "    Reflection: do you agree with the cot yes or no\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(reflect_prompt_template.format(question=question,answer_choices=answer_choices,cot_trigger=cot_trigger,\n",
    "                                     cot=cot,answer_extraction=answer_extraction,\n",
    "                                     answer=answer,reflection_prompt=reflection_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Question: ('Animals may fight, make threatening sounds, and act aggressively toward members of the same species. These behaviors usually occur as the result of',)\n",
      "    Answer_choices: ['competition', 'conservation', 'decomposition', 'pollution']\n",
      "\n",
      "    Answer: Let's think step by step. Aggression is needed to defend something, one needs to defend their spot when they are in competition\n",
      "    Therefore, the answer is competition\n",
      "    \n",
      "    Reflection: do you agree with the cot yes or no\n",
      "    Great reasoning mate!\n",
      "\n",
      "    Based on the text above the answer is:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ans_prompt_template.format(question=question,answer_choices=answer_choices,cot_trigger=cot_trigger,\n",
    "                                     cot=cot,answer_extraction=answer_extraction,\n",
    "                                     answer=answer,reflection_prompt=reflection_prompt,\n",
    "                                     reflection=reflection,reflect_answer_extraction=reflect_answer_extraction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = Collection.load_thoughtsource_100(names='strategy_qa',load_pregenerated_cots=True) #random_sample=False?\n",
    "coll = coll.select(split=\"all\", number_samples=1)\n",
    "coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='cohere') #have one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name        |   Train | Valid   | Test   |\n",
       "|-------------|---------|---------|--------|\n",
       "| strategy_qa |       1 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating strategy_qa...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_dict = {\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\", \n",
    "    'answer':\"\", \n",
    "    'cot': \"\", \n",
    "    'reflection_prompt':\"Double check this\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?'\n",
    "}\n",
    "metareason = coll.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = Collection.to_Collection(metareason,\"strategy_qa\",'train','file_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'ref_id', 'question', 'type', 'choices', 'context', 'cot', 'answer', 'generated_cot', 'feedback'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['strategy_qa']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to dataloader\n",
    "\n",
    "\"\"\"Creates json and collection from Thoughtsource ouptut; chain_output from chain_generation\"\"\"\n",
    "def to_Collection(chain_output,dataset_name,split,file_name):\n",
    "\n",
    "    #Force langchain into TS structure \n",
    "    ts_set = {dataset_name:{split:chain_output}}\n",
    "\n",
    "    #create and collect a json to make collection\n",
    "    with open(f\"{file_name}.json\", \"w\") as outfile:\n",
    "        json.dump(ts_set, outfile)\n",
    "    collect = Collection.from_json('sample.json')\n",
    "\n",
    "    return collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      | Train   | Valid   |   Test |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree | -       | -       |     30 |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Force langchain into TS structure \n",
    "worldtree_new = {'worldtree':{'test':metareason}}\n",
    "\n",
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(worldtree_new, outfile)\n",
    "collect = Collection.from_json('sample.json')\n",
    "\n",
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion: with these prompts, there is no new information and no changed answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating worldtree...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_dict = {\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\", \n",
    "    'answer':\"\", \n",
    "    'cot': \"\", \n",
    "    'reflection_prompt':\"Critique the reasoning above\",\n",
    "    'reflect_answer_extraction':'Based on the reasoning and the reflection, what is the final answer? (A-D)?'\n",
    "}\n",
    "metareason = coll.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name      | Train   | Valid   |   Test |\n",
       "|-----------|---------|---------|--------|\n",
       "| worldtree | -       | -       |     30 |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'strategy_qa', 'svamp']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Force langchain into TS structure \n",
    "worldtree_new = {'worldtree':{'test':metareason}}\n",
    "\n",
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(worldtree_new, outfile)\n",
    "collect = Collection.from_json('sample.json')\n",
    "\n",
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatgpt seems to be a bad corrector, what about its competitors?\n",
    "#but davinci is no better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '8b8ddb55-e1fc-4fac-85c7-333a76cacd91',\n",
       "  'answer_extraction': 'Therefore, among A through D, the answer is',\n",
       "  'answer_extraction_template': '',\n",
       "  'answer_extraction_text': 'self_reflection',\n",
       "  'answer': 'The definite answer is B) There is a change in the appearance of the objects.',\n",
       "  'correct_answer': None}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example cot and ans\n",
    "\n",
    "metareason[0]['generated_cot'][3]\n",
    "metareason[0]['generated_cot'][3]['answers']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: evaluate in annotator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy_qa and yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coll = Collection.load_thoughtsource_100(names='strategy_qa',load_pregenerated_cots=True)\n",
    "# coll = coll.select(split=\"all\", number_samples=1)\n",
    "# coll.select_generated_cots(cot_trigger = \"kojima-01\", api_service='openai') #have one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '6067839f-c5f5-494b-a71c-10dde2739954',\n",
       "  'fragments_version': '0.01',\n",
       "  'instruction': None,\n",
       "  'cot_trigger': 'kojima-01',\n",
       "  'cot_trigger_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}',\n",
       "  'prompt_text': '',\n",
       "  'cot': ' First, we need to convert 900,000 pounds to US dollars. As of June 2020, 1 pound is equal to 1.25 US dollars. So, 900,000 pounds is equal to 1,125,000 US dollars.\\n\\nNext, we need to compare this amount to the net worth of a billionaire. According to Forbes, the minimum net worth of a US billionaire is currently $1.1 billion.\\n\\nTherefore, a 900,000 pound net worth person would not be an American billionaire if they exchange currency in June 2020.',\n",
       "  'answers': [{'id': '5d8d5fee-f1ee-4d8f-bd71-8261f260519c',\n",
       "    'answer_extraction': 'kojima-yes-no',\n",
       "    'answer_extraction_template': '{instruction}\\n\\n{question}\\n{answer_choices}\\n\\n{cot_trigger}{cot}\\n{answer_extraction}',\n",
       "    'answer_extraction_text': '',\n",
       "    'answer': ' No.',\n",
       "    'correct_answer': False}],\n",
       "  'author': 'thoughtsource',\n",
       "  'date': '2023/02/15 15:38:26',\n",
       "  'api_service': 'openai',\n",
       "  'model': \"{'name': 'text-davinci-003', 'temperature': 0, 'max_tokens': 512}\",\n",
       "  'comment': '',\n",
       "  'annotations': []}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll['strategy_qa']['train'][0]['generated_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>kojima-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>text-davinci-003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   kojima-01\n",
       "            text-davinci-003\n",
       "strategy_qa              0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot.stats import evaluation_as_table\n",
    "eval = coll.evaluate()\n",
    "evaluation_as_table(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\", \n",
    "    'answer':\"\", \n",
    "    'cot': \"\", \n",
    "    'reflection_prompt':\"Do you have any reason to believe that the reasoning or the answer might be wrong? Answer with one word Yes or No\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?'\n",
    "}\n",
    "metareason = coll.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)\n",
    "#These prompts only let the model say no reason to believe the answer is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating strategy_qa...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_dict = {\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\", \n",
    "    'answer':\"\", \n",
    "    'cot': \"\", \n",
    "    'reflection_prompt':\"Improve the step-by-step thinking\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?'\n",
    "}\n",
    "metareason = coll.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating strategy_qa...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_dict = {\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\", \n",
    "    'answer':\"\", \n",
    "    'cot': \"\", \n",
    "    'reflection_prompt':\"Is there any irrelevant or incorrect information in the Answer\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?',\n",
    "    'model_name':\"gpt-3.5-turbo\"\n",
    "}\n",
    "metareason = coll.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name        |   Train | Valid   | Test   |\n",
       "|-------------|---------|---------|--------|\n",
       "| strategy_qa |      30 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_new = {'strategy_qa':{'train':metareason}}\n",
    "\n",
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(st_new, outfile)\n",
    "collect = Collection.from_json('sample.json')\n",
    "\n",
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '03e45537-96e6-4f2d-adfc-86137df0fae0',\n",
       " 'fragments_version': '0.01',\n",
       " 'instruction': '',\n",
       " 'cot_trigger': \"Answer: Let's think step by step.\",\n",
       " 'cot_trigger_template': '',\n",
       " 'prompt_text': '',\n",
       " 'cot': 'Yes.',\n",
       " 'answers': [{'id': 'cde8940d-e39c-45b4-be9d-1ad14c4d48c6',\n",
       "   'answer_extraction': 'Therefore, among A through D, the answer is',\n",
       "   'answer_extraction_template': '',\n",
       "   'answer_extraction_text': 'self_reflection',\n",
       "   'answer': 'The definite answer is False.',\n",
       "   'correct_answer': True}],\n",
       " 'author': '',\n",
       " 'date': '2023/03/16 13:32:18',\n",
       " 'api_service': '',\n",
       " 'model': \"{'name': '', 'temperature': 0, 'max_tokens': 800}\",\n",
       " 'comment': 'self_reflection cot',\n",
       " 'annotations': []}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect['strategy_qa']['train'][0]['generated_cot'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6958ac68108b4e299e9ff80fff699c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4403fa0d648d42818ce43258ddbf6423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2207 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324b159afd9c419b832aaa15543974b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1664 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31552c77638641bea8a34ae9a9630aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/496 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['strategy_qa.train.accuracy.command-xlarge-nightly.None_kojima-01_kojima-yes-no']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>kojima-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>command-xlarge-nightly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>strategy_qa</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldtree</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         kojima-01\n",
       "            command-xlarge-nightly\n",
       "strategy_qa                    0.6\n",
       "worldtree                      NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cot.stats import evaluation_as_table\n",
    "eval = coll.evaluate()\n",
    "evaluation_as_table(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f0e20013784c40b9c7b5a14cf987dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"strategy_qa.train.accuracy.._Answer: Let's think step by step._Therefore, among A through D, the answer is\", 'strategy_qa.train.accuracy.command-xlarge-nightly.None_kojima-01_kojima-yes-no']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcot\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m evaluation_as_table\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39meval\u001b[39m \u001b[39m=\u001b[39m collect\u001b[39m.\u001b[39mevaluate()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robertpraas/Desktop/ThoughtSource/notebooks/langchain_experiments.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m evaluation_as_table(\u001b[39meval\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/ThoughtSource/libs/cot/cot/stats.py:363\u001b[0m, in \u001b[0;36mevaluation_as_table\u001b[0;34m(eval)\u001b[0m\n\u001b[1;32m    361\u001b[0m i \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mgpt-3-5-turbo\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    362\u001b[0m dataset,split,metric,model,prompt \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mgpt-3-5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m models:\n\u001b[1;32m    365\u001b[0m     models\u001b[39m.\u001b[39mappend(model)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "from cot.stats import evaluation_as_table\n",
    "eval = collect.evaluate()\n",
    "evaluation_as_table(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'strategy_qa'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">      </span><span style=\"color: #008000; text-decoration-color: #008000\">'train'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">         </span><span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">''</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"_Answer: Let's think step by step._Therefore, among A through D, the answer is\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.566667</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'command-xlarge-nightly'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'None_kojima-01_kojima-yes-no'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">         </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">      </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'strategy_qa'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m      \u001b[0m\u001b[32m'train'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m         \u001b[0m\u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m            \u001b[0m\u001b[32m''\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"_Answer: Let's think step by step._Therefore, among A through D, the answer is\"\u001b[0m: \u001b[1;36m0.566667\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m            \u001b[0m\u001b[32m'command-xlarge-nightly'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'None_kojima-01_kojima-yes-no'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m         \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m      \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.pretty import pprint\n",
    "pprint(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating strategy_qa...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_dict = {\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\", \n",
    "    'answer':\"\", \n",
    "    'cot': \"\", \n",
    "    'reflection_prompt':\"The goal is to correct the Answer if needed, let's think step by step\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?',\n",
    "    'model_name':\"gpt-3.5-turbo\"\n",
    "}\n",
    "metareason = coll.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name        |   Train | Valid   | Test   |\n",
       "|-------------|---------|---------|--------|\n",
       "| strategy_qa |      30 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_new = {'strategy_qa':{'train':metareason}}\n",
    "\n",
    "#create and collect a json to make collection\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(st_new, outfile)\n",
    "collect = Collection.from_json('sample.json')\n",
    "\n",
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating strategy_qa...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Increase lenght of prompt\"\"\"\n",
    "input_dict = {\n",
    "    \"cot_trigger\": \"Answer: Let's think step by step.\",\n",
    "    \"answer_extraction\": \"Therefore, among A through D, the answer is\", \n",
    "    'answer':\"\", \n",
    "    'cot': \"\", \n",
    "    'reflection_prompt':\"Attempt to give a better Answer than the one before\",\n",
    "    'reflect_answer_extraction':'Based on the reflection, what is the definite answer?',\n",
    "    'model_name':\"gpt-4\"\n",
    "}\n",
    "metareason = coll.metareason_flexible(chain=reflect_overall_chain,input_dict=input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version              Editable project location\n",
      "----------------------------- -------------------- -------------------------------------------------\n",
      "accelerate                    0.16.0\n",
      "addict                        2.4.0\n",
      "aiohttp                       3.8.4\n",
      "aiosignal                     1.2.0\n",
      "alabaster                     0.7.12\n",
      "altair                        4.2.0\n",
      "anaconda-client               1.9.0\n",
      "anaconda-navigator            2.1.4\n",
      "anaconda-project              0.10.2\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "applaunchservices             0.2.1\n",
      "appnope                       0.1.2\n",
      "appscript                     1.1.2\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.2\n",
      "astroid                       2.6.6\n",
      "astropy                       5.0.4\n",
      "asttokens                     2.0.5\n",
      "async-timeout                 4.0.1\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.statistics          0.1.0\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "backports.zoneinfo            0.2.1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.9.3\n",
      "binaryornot                   0.4.4\n",
      "bitarray                      2.4.1\n",
      "bkcharts                      0.2\n",
      "black                         22.1.0\n",
      "bleach                        5.0.1\n",
      "blinker                       1.4\n",
      "blis                          0.7.9\n",
      "bokeh                         2.4.2\n",
      "boto3                         1.21.32\n",
      "botocore                      1.24.32\n",
      "Bottleneck                    1.3.4\n",
      "brotlipy                      0.7.0\n",
      "bs4                           0.0.1\n",
      "cachetools                    4.2.2\n",
      "catalogue                     2.0.8\n",
      "certifi                       2021.10.8\n",
      "cffi                          1.15.0\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "chatGPT                       0.3.9\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.0.0\n",
      "clyent                        1.2.2\n",
      "cohere                        3.3.2\n",
      "colorama                      0.4.4\n",
      "colorcet                      2.0.6\n",
      "commonmark                    0.9.1\n",
      "conda                         4.12.0\n",
      "conda-build                   3.21.8\n",
      "conda-content-trust           0+unknown\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        1.8.1\n",
      "conda-repo-cli                1.0.4\n",
      "conda-token                   0.3.0\n",
      "conda-verify                  3.4.2\n",
      "confection                    0.0.3\n",
      "constantly                    15.1.0\n",
      "cookiecutter                  1.7.3\n",
      "cot                           0.0.1                /Users/robertpraas/Desktop/ThoughtSource/libs/cot\n",
      "cryptography                  3.4.8\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "cymem                         2.0.7\n",
      "Cython                        0.29.28\n",
      "cytoolz                       0.11.0\n",
      "daal4py                       2021.5.0\n",
      "dacite                        1.8.0\n",
      "dask                          2022.2.1\n",
      "dataclasses-json              0.5.7\n",
      "datasets                      2.1.0\n",
      "datashader                    0.13.0\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.6\n",
      "distributed                   2022.2.1\n",
      "docutils                      0.17.1\n",
      "dynamicprompts                0.1.1\n",
      "en-core-web-sm                3.4.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     0.8.3\n",
      "fastjsonschema                2.15.1\n",
      "filelock                      3.6.0\n",
      "flake8                        3.8.4\n",
      "Flask                         1.1.2\n",
      "flatdict                      4.0.1\n",
      "fonttools                     4.25.0\n",
      "frozenlist                    1.2.0\n",
      "fsspec                        2022.2.0\n",
      "future                        0.18.2\n",
      "galai                         1.1.6\n",
      "gensim                        4.1.2\n",
      "gitdb                         4.0.9\n",
      "GitPython                     3.1.27\n",
      "glob2                         0.7\n",
      "gmpy2                         2.1.2\n",
      "google                        3.0.0\n",
      "google-api-core               2.8.2\n",
      "google-auth                   1.33.0\n",
      "google-cloud-core             2.3.1\n",
      "google-cloud-firestore        2.5.3\n",
      "google-cloud-storage          1.31.0\n",
      "google-crc32c                 1.1.2\n",
      "google-resumable-media        1.3.1\n",
      "google-search-results         2.4.1\n",
      "googleapis-common-protos      1.56.3\n",
      "googlesearch-python           1.1.0\n",
      "greenlet                      2.0.1\n",
      "grpcio                        1.47.0\n",
      "grpcio-status                 1.47.0\n",
      "h5py                          3.6.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.14.8\n",
      "html5lib                      1.1\n",
      "huggingface-hub               0.11.1\n",
      "hvplot                        0.7.3\n",
      "hyperlink                     21.0.0\n",
      "idna                          2.10\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.9.0\n",
      "imagesize                     1.3.0\n",
      "importlib-metadata            4.11.3\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.5\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.9.1\n",
      "ipython                       8.2.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.5\n",
      "isort                         5.0.9\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jdcal                         1.4.1\n",
      "jedi                          0.18.1\n",
      "Jinja2                        3.1.2\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.6\n",
      "jsonmerge                     1.9.0\n",
      "jsonschema                    4.4.0\n",
      "jupyter                       1.0.0\n",
      "jupyter-client                6.1.12\n",
      "jupyter-console               6.4.0\n",
      "jupyter-core                  4.9.2\n",
      "jupyter-server                1.13.5\n",
      "jupyterlab                    3.3.2\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-server             2.10.3\n",
      "jupyterlab-widgets            1.0.0\n",
      "keyring                       23.4.0\n",
      "kiwisolver                    1.3.2\n",
      "langchain                     0.0.113\n",
      "langcodes                     3.3.0\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "llvmlite                      0.38.0\n",
      "locket                        0.2.1\n",
      "lxml                          4.9.0\n",
      "Markdown                      3.4.1\n",
      "MarkupSafe                    2.0.1\n",
      "marshmallow                   3.19.0\n",
      "marshmallow-enum              1.5.1\n",
      "matplotlib                    3.5.1\n",
      "matplotlib-inline             0.1.2\n",
      "mccabe                        0.6.1\n",
      "mistune                       2.0.5\n",
      "mkl-fft                       1.3.1\n",
      "mkl-random                    1.2.2\n",
      "mkl-service                   2.4.0\n",
      "mmcls                         0.24.1\n",
      "mmcv-full                     1.7.0\n",
      "mock                          4.0.3\n",
      "mpmath                        1.2.1\n",
      "mpu                           0.23.1\n",
      "msgpack                       1.0.2\n",
      "multidict                     5.2.0\n",
      "multipledispatch              0.6.0\n",
      "multiprocess                  0.70.14\n",
      "munkres                       1.1.4\n",
      "murmurhash                    1.0.9\n",
      "mypy-extensions               0.4.3\n",
      "navigator-updater             0.2.1\n",
      "nbclassic                     0.3.5\n",
      "nbclient                      0.6.8\n",
      "nbconvert                     7.2.9\n",
      "nbformat                      5.3.0\n",
      "nbimporter                    0.3.4\n",
      "nbmake                        1.4\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.7.1\n",
      "nltk                          3.7\n",
      "nose                          1.3.7\n",
      "notebook                      6.4.8\n",
      "numba                         0.55.1\n",
      "numexpr                       2.8.1\n",
      "numpy                         1.21.5\n",
      "numpydoc                      1.2\n",
      "olefile                       0.46\n",
      "openai                        0.27.2\n",
      "opencv-python                 4.6.0.66\n",
      "openpyxl                      3.0.9\n",
      "packaging                     21.3\n",
      "pandas                        1.4.2\n",
      "pandas-stubs                  1.2.0.61\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.13.0\n",
      "parallelformers               1.2.7\n",
      "param                         1.12.0\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathspec                      0.11.0\n",
      "pathy                         0.10.1\n",
      "patsy                         0.5.2\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.0.1\n",
      "pip                           22.1.2\n",
      "pkginfo                       1.8.2\n",
      "platformdirs                  3.0.0\n",
      "playwright                    1.30.0\n",
      "plotly                        5.10.0\n",
      "pluggy                        1.0.0\n",
      "poyo                          0.5.0\n",
      "preshed                       3.0.8\n",
      "prettytable                   3.5.0\n",
      "prometheus-client             0.13.1\n",
      "prompt-toolkit                3.0.20\n",
      "Protego                       0.1.16\n",
      "proto-plus                    1.20.6\n",
      "protobuf                      3.19.1\n",
      "psutil                        5.8.0\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "py                            1.11.0\n",
      "pyarrow                       8.0.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.6.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.6\n",
      "pycurl                        7.44.1\n",
      "pydantic                      1.10.4\n",
      "pydeck                        0.7.1\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.1.1\n",
      "pyee                          9.0.4\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      2.2.0\n",
      "Pygments                      2.11.2\n",
      "PyHamcrest                    2.0.2\n",
      "PyJWT                         2.1.0\n",
      "pylint                        2.9.6\n",
      "pyls-spyder                   0.4.0\n",
      "Pympler                       1.0.1\n",
      "pyodbc                        4.0.32\n",
      "pyOpenSSL                     21.0.0\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.1.1\n",
      "python-dateutil               2.8.2\n",
      "python-lsp-black              1.0.0\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.2.4\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.0\n",
      "pytz                          2021.3\n",
      "pytz-deprecation-shim         0.1.0.post0\n",
      "pyviz-comms                   2.0.2\n",
      "PyWavelets                    1.3.0\n",
      "PyYAML                        6.0\n",
      "pyzmq                         22.3.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.1.10\n",
      "QtAwesome                     1.0.3\n",
      "qtconsole                     5.3.0\n",
      "QtPy                          2.0.1\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.3.15\n",
      "requests                      2.28.1\n",
      "requests-file                 1.5.1\n",
      "responses                     0.18.0\n",
      "retry                         0.9.2\n",
      "revChatGPT                    1.0.7\n",
      "rich                          12.6.0\n",
      "rope                          0.22.0\n",
      "rsa                           4.7.2\n",
      "Rtree                         0.9.7\n",
      "ruamel-yaml-conda             0.15.100\n",
      "s3transfer                    0.5.0\n",
      "scikit-image                  0.19.2\n",
      "scikit-learn                  1.0.2\n",
      "scikit-learn-intelex          2021.20220215.132722\n",
      "scipy                         1.7.3\n",
      "Scrapy                        2.6.1\n",
      "seaborn                       0.11.2\n",
      "semanticscholar               0.2.1\n",
      "semver                        2.13.0\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    61.2.0\n",
      "sip                           4.19.13\n",
      "six                           1.16.0\n",
      "smart-open                    6.3.0\n",
      "smmap                         5.0.0\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcollections             2.1.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.1\n",
      "spacy                         3.4.2\n",
      "spacy-legacy                  3.0.11\n",
      "spacy-loggers                 1.0.4\n",
      "Sphinx                        4.4.0\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.1.5\n",
      "spyder-kernels                2.1.3\n",
      "SQLAlchemy                    1.4.32\n",
      "srsly                         2.4.5\n",
      "stack-data                    0.2.0\n",
      "statsmodels                   0.13.2\n",
      "streamlit                     1.10.0\n",
      "streamlit-analytics           0.3.1\n",
      "streamlit-metrics             0.1.0\n",
      "sympy                         1.10.1\n",
      "tables                        3.6.1\n",
      "tabulate                      0.8.10\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.1\n",
      "terminado                     0.13.1\n",
      "testpath                      0.5.0\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "thinc                         8.1.6\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss                       0.4\n",
      "tinycss2                      1.1.1\n",
      "tldextract                    3.2.0\n",
      "tokenizers                    0.13.2\n",
      "toml                          0.10.2\n",
      "tomli                         1.2.2\n",
      "toolz                         0.11.2\n",
      "torch                         1.13.0\n",
      "torchvision                   0.14.0\n",
      "tornado                       6.1\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.9.0\n",
      "transformers                  4.25.1\n",
      "Twisted                       22.2.0\n",
      "typed-ast                     1.4.3\n",
      "typer                         0.4.2\n",
      "typing_extensions             4.4.0\n",
      "typing-inspect                0.8.0\n",
      "tzdata                        2022.1\n",
      "tzlocal                       4.2\n",
      "ujson                         5.1.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.9\n",
      "validators                    0.19.0\n",
      "w3lib                         1.21.0\n",
      "wasabi                        0.10.1\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.0.3\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.5.2\n",
      "wrapt                         1.12.1\n",
      "wurlitzer                     3.0.2\n",
      "xarray                        0.20.1\n",
      "xlrd                          2.0.1\n",
      "XlsxWriter                    3.0.3\n",
      "xlwings                       0.24.9\n",
      "xxhash                        3.2.0\n",
      "yapf                          0.31.0\n",
      "yarl                          1.6.3\n",
      "zict                          2.0.0\n",
      "zipp                          3.7.0\n",
      "zope.interface                5.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Collection.to_Collection(metareason,\"strategy_qa\",'train','long_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "| Name        |   Train | Valid   | Test   |\n",
       "|-------------|---------|---------|--------|\n",
       "| strategy_qa |      20 | -       | -      |\n",
       "\n",
       "Not loaded: ['aqua', 'asdiv', 'commonsense_qa', 'entailment_bank', 'gsm8k', 'mawps', 'med_qa', 'medmc_qa', 'open_book_qa', 'pubmed_qa', 'qed', 'svamp', 'worldtree']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1983f0119042709d99382b9715b866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"color: #008000; text-decoration-color: #008000\">'strategy_qa'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">      </span><span style=\"color: #008000; text-decoration-color: #008000\">'train'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">         </span><span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">''</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"_Answer: Let's think step by step._Therefore, among A through D, the answer is\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.45</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'command-xlarge-nightly'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'None_kojima-01_kojima-yes-no'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">         </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">      </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m   \u001b[0m\u001b[32m'strategy_qa'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m      \u001b[0m\u001b[32m'train'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m         \u001b[0m\u001b[32m'accuracy'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32m            \u001b[0m\u001b[32m''\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m\"_Answer: Let's think step by step._Therefore, among A through D, the answer is\"\u001b[0m: \u001b[1;36m0.45\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m            \u001b[0m\u001b[32m'command-xlarge-nightly'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'None_kojima-01_kojima-yes-no'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m         \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m      \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.pretty import pprint\n",
    "eval = test.evaluate()\n",
    "pprint(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a73e7e6fa544bc998d385b079a4a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.dump(\"test_evaluated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
